# name: train-daily

# permissions:
#   contents: write  # for the auto-commit

# on:
#   schedule:
#     - cron: "0 19 * * *"   # 19:00 UTC (00:00 PKT)
#   workflow_dispatch:

# jobs:
#   train:
#     runs-on: ubuntu-latest
#     steps:
#       - uses: actions/checkout@v4

#       # main env (your project uses 3.11)
#       - uses: actions/setup-python@v5
#         with:
#           python-version: "3.11"

#       - name: Install project deps
#         run: pip install -r requirements.txt

#       - name: Train (multi-horizon)
#         run: python src/train.py

#       # --- sync best models into models/latest for Streamlit ---
#       - name: Sync models/latest directory
#         shell: bash
#         run: |
#           set -euo pipefail

#           echo "=== MODELS TREE (before sync) ==="
#           ls -R models || true

#           mkdir -p models/latest
#           rm -f models/latest/* || true

#           # pick the folder that actually got the newest joblib
#           newest_joblib="$(find models -type f -name '*tplus*.joblib' -printf '%T@ %p\n' | sort -n | tail -n1 | cut -d' ' -f2- || true)"
#           if [ -n "${newest_joblib}" ]; then
#             src_dir="$(dirname "${newest_joblib}")"
#           else
#             src_dir="models"
#           fi

#           echo "Using source directory: ${src_dir}"

#           find "${src_dir}" -maxdepth 1 -name '*tplus24.joblib' -exec cp -t models/latest {} + || true
#           find "${src_dir}" -maxdepth 1 -name '*tplus48.joblib' -exec cp -t models/latest {} + || true
#           find "${src_dir}" -maxdepth 1 -name '*tplus72.joblib' -exec cp -t models/latest {} + || true

#           # copy metadata
#           if [ -f "${src_dir}/features.json" ]; then
#             cp "${src_dir}/features.json" models/latest/
#           elif [ -f "models/features.json" ]; then
#             cp "models/features.json" models/latest/
#           fi

#           if [ -f "${src_dir}/report.json" ]; then
#             cp "${src_dir}/report.json" models/latest/
#           elif [ -f "models/report.json" ]; then
#             cp "models/report.json" models/latest/
#           fi

#           echo "=== models/latest content ==="
#           ls -l models/latest || true

#       - name: Commit models/latest back to repo
#         uses: stefanzweifel/git-auto-commit-action@v5
#         with:
#           commit_message: "chore(models): refresh models/latest from train-daily"

#       # detect if secrets exist
#       - name: Set Hopsworks presence flag
#         shell: bash
#         run: |
#           if [ -n "${{ secrets.HOPSWORKS_PROJECT }}" ] && [ -n "${{ secrets.HOPSWORKS_API_KEY }}" ]; then
#             echo "HAVE_HOPSWORKS=true" >> "$GITHUB_ENV"
#           else
#             echo "HAVE_HOPSWORKS=false" >> "$GITHUB_ENV"
#           fi

#       # push features
#       - name: Switch to Python 3.10 for Hopsworks feature push
#         if: ${{ env.HAVE_HOPSWORKS == 'true' }}
#         uses: actions/setup-python@v5
#         with:
#           python-version: "3.10"

#       - name: Push features to Hopsworks
#         if: ${{ env.HAVE_HOPSWORKS == 'true' }}
#         env:
#           HOPSWORKS_PROJECT: ${{ secrets.HOPSWORKS_PROJECT }}
#           HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
#         run: |
#           set -e
#           python -V
#           pip install --upgrade "pip<25"
#           # clean old
#           pip uninstall -y hopsworks hsml hopsworks-common || true
#           # install hsfs python-engine + deps
#           pip install \
#             "hsfs[python]==3.9.0rc7" \
#             "protobuf>=4.25.4,<5" \
#             "confluent-kafka<3" \
#             pyhive thrift avro
#           python src/push_features_hopsworks.py

#       # upload models artifact (so you can download from Actions if needed)
#       - uses: actions/upload-artifact@v4
#         with:
#           name: models
#           path: models/
























name: train-daily

permissions:
  contents: write  # needed for auto-commit of models/latest

on:
  schedule:
    - cron: "0 19 * * *"   # every day at 19:00 UTC (00:00 PKT)
  workflow_dispatch:

jobs:
  train:
    runs-on: ubuntu-latest

    steps:
      # 1) get code
      - name: Checkout repo
        uses: actions/checkout@v4

      # 2) main Python (project uses 3.11)
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # 3) install project deps
      - name: Install dependencies
        run: pip install -r requirements.txt

      # 4) train all horizons (24/48/72)
      - name: Train (multi-horizon)
        run: python src/train.py

      # 5) sync the newest trained models into models/latest
      - name: Sync models/latest directory
        shell: bash
        run: |
          set -euo pipefail

          echo "=== MODELS TREE (before sync) ==="
          ls -R models || true

          mkdir -p models/latest
          rm -f models/latest/* || true

          # find the folder that actually produced the latest joblib
          newest_joblib="$(find models -type f -name '*tplus*.joblib' -printf '%T@ %p\n' | sort -n | tail -n1 | cut -d' ' -f2- || true)"
          if [ -n "${newest_joblib}" ]; then
            src_dir="$(dirname "${newest_joblib}")"
          else
            src_dir="models"
          fi

          echo "Using source directory: ${src_dir}"

          # copy the 3 horizons if present
          find "${src_dir}" -maxdepth 1 -name '*tplus24.joblib' -exec cp -t models/latest {} + || true
          find "${src_dir}" -maxdepth 1 -name '*tplus48.joblib' -exec cp -t models/latest {} + || true
          find "${src_dir}" -maxdepth 1 -name '*tplus72.joblib' -exec cp -t models/latest {} + || true

          # copy metadata
          if [ -f "${src_dir}/features.json" ]; then
            cp "${src_dir}/features.json" models/latest/
          elif [ -f "models/features.json" ]; then
            cp "models/features.json" models/latest/
          fi

          if [ -f "${src_dir}/report.json" ]; then
            cp "${src_dir}/report.json" models/latest/
          elif [ -f "models/report.json" ]; then
            cp "models/report.json" models/latest/
          fi

          echo "=== models/latest content ==="
          ls -l models/latest || true

      # 6) commit models/latest back to the repo (optional but handy)
      - name: Commit models/latest back to repo
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore(models): refresh models/latest from train-daily"

      # 7) check if Hopsworks secrets are present
      - name: Set Hopsworks presence flag
        shell: bash
        run: |
          if [ -n "${{ secrets.HOPSWORKS_PROJECT }}" ] && [ -n "${{ secrets.HOPSWORKS_API_KEY }}" ]; then
            echo "HAVE_HOPSWORKS=true" >> "$GITHUB_ENV"
          else
            echo "HAVE_HOPSWORKS=false" >> "$GITHUB_ENV"
          fi

      # 8) optional: push features to Hopsworks (only if secrets exist)
      - name: Set up Python 3.10 for Hopsworks feature push
        if: ${{ env.HAVE_HOPSWORKS == 'true' }}
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Push features to Hopsworks
        if: ${{ env.HAVE_HOPSWORKS == 'true' }}
        env:
          HOPSWORKS_PROJECT: ${{ secrets.HOPSWORKS_PROJECT }}
          HOPSWORKS_API_KEY: ${{ secrets.HOPSWORKS_API_KEY }}
        run: |
          set -e
          python -V
          pip install --upgrade "pip<25"
          # clean any earlier installs so deps don't clash
          pip uninstall -y hopsworks hsml hopsworks-common || true
          # install just what push_features_hopsworks.py uses
          pip install \
            "hsfs[python]==3.9.0rc7" \
            "protobuf>=4.25.4,<5" \
            "confluent-kafka<3" \
            pyhive thrift avro
          python src/push_features_hopsworks.py

      # 9) upload models as artifact (easy download from Actions)
      - name: Upload models artifact
        uses: actions/upload-artifact@v4
        with:
          name: models
          path: models/
